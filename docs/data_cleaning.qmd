---
title: "Data cleaning"
format: html
---


```{r setup}
#| include: false
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=",")
})

library(tidyverse)
library(rgeos)
library(progress)
library(svglite)
library(patchwork)
```

```{r data}
ids <- read.csv("../data/apartment_simulations.csv") |>
  mutate(bfa = paste(building_id, floor_id, apartment_id, sep = "_"))
clusters <- read.csv2("../data/all_flats_clustered.csv", sep = ",")
```


## Descriptives

The Neufert 4.0 dataset comprised data from a total of _N_ = `r nrow(ids)` apartments.

```{r}
raw_data <- ids
ids <- ids |> filter(
    No_floor >= 0 & No_floor < 7 &
    total_area >= 25 & total_area <= 200 &
    !is.na(room_sunlight) & !is.na(room_noise) &
    room_noise > 0 & room_sunlight > 0 &
    room_number < 6
)
```

In the first step, we excluded flats that were either underground or above 6^th^ floor (_n_ = `r raw_data[raw_data$No_floor < 0 | raw_data$No_floor > 6, ] |> nrow()`), had a total are outside of the 25-200 m^2^ range (_n_ = `r raw_data[raw_data$total_area < 25 | raw_data$total_area > 200, ] |> nrow()`), lacked data on room noise (_n_ = `r raw_data |> filter(is.na(room_noise)) |> nrow()`) or room sunlight (_n_ = `r raw_data |> filter(is.na(room_sunlight)) |> nrow()`), or had a value of zero for either of these two variables (_n_ = `r raw_data |> filter(room_noise == 0 | room_sunlight == 0) |> nrow()`). As only a small number of flats (_n_ = `r raw_data |> filter(room_number > 5) |> nrow()`) had more than five rooms, these were also excluded. This resulted in a sample size of _N_ = `r nrow(ids)` apartments, whose characteristics are shown in @fig-desc.

```{r}
#| fig-cap: Distributions of the main variables of interest after the initial data cleaning.
#| label: fig-desc 
#| fig-height: 8

p_floor <- ids |> mutate(No_floor = factor(No_floor)) |> ggplot(aes(x = No_floor)) + geom_bar() + labs(x = "Floor")

p_rooms <- ids |> mutate(room_number = factor(room_number)) |> ggplot(aes(x = room_number)) + geom_bar() + labs(x = "Number of rooms")

p_area <- ids |> ggplot(aes(x = total_area)) + geom_histogram() + labs(x = "Total area (m2)")

p_light <- ids |> ggplot(aes(x = room_sunlight)) + geom_histogram() + labs(x = "Average room sunlight (klx)")

p_noise <- ids |> ggplot(aes(x = room_noise)) + geom_histogram() + labs(x = "Average room noise (dB)")

( p_floor | p_rooms ) / p_area / ( p_light | p_noise )
```

## Shape clusters

To identify clusters that contain apartments of with the same layout, we devised the following algorithm:

First, to account for potential rotation of the apartments, we oriented them along the horizontal (x-axis) and the vertical (y-axis). This was done byt aligning the longest polygon edge within each apartments along the horizontal.

Next, we converted the vector graphics representation of the apartments to 224&times;224 black and white raster representation that contained only area geometries (rooms, corridors, shafts, balconies _etc._ but not walls, columns, doors, or windows). Each such 224&times;224 matrix contained only values of 0 (black) and 1 (white).

These matrices were then used to compare to get a measure of distance between the apartment geometries. The apartments were first grouped according to number of rooms. Within each group, we then selected a random apartment as a reference matrix ($\mathbf{A}$) and calculated the sum of squared difference between this reference and all other apartnent matrices ($\mathbf{B}$):

$$SS = \sum_{i = 1}^{n}\sum_{j = 1}^{n}(\mathbf{B}_{ij} - \mathbf{A}_{ij})^2$$

where $n$ = 224, the number of pixels per dimension.

After the initial aligning of the floor plans along the x and y axes, there remained eight possible orientations each floor plan could have (see @fig-orient). For this reason, each floor plan matrix was transformed into eight different matrices that reflected these rotattions and only then compared to the reference using the sum of squares measure. This resulted in eight distance values per floor plan, yielding an eight-dimensional difference space, with each floorplan representing a point in this space and the reference flat positioned at its origin.


```{r}
#| fig-cap: All eight possible orientations of a single aligned apartment representation
#| label: fig-orient 
#| fig-height: 5
#| fig-width: 5

img <- magick::image_read(paste0("../img/example_floorplan.png"))

mar_orig <- par()$mar
par(mfrow = c(3, 3), mar = rep(0, 4))
for (i in 0:3) {
plot(magick::image_rotate(img, i * 90))
plot(magick::image_flip(magick::image_rotate(img, i * 90)))
if (i == 1) plot.new()
}

par(mfrow = c(1, 1), mar = mar_orig)
```

In order to further expand this difference space, we selected another floor plan as reference and repeated this process. This floor plan was chosen from the middle of the distance distributions in the first iteration. Thee resulting 16-dimensional data set was then passed to the Self-Organising Map algorithm (SOM, Kohonen...) with a grid size equal to $floor(\sqrt{n})$, where $n$ represents the number of floor plans with a given number of rooms. This procedure yielded grid position for each of the analysed floor plans, clustering them according to shape.

The above-described algorithm produced a somewhat liberal clusters, occasionally grouping dissimilar floor plans into a single cluster and so a further step was implemented to refine the clustering. Within each of the SOM clusters, we started by designating the first (position was arbitrary) floor plan as the reference and once again calculated the distance between it and the eight orientations of all other floor plans in the same SOM cluster. If the smallest of the eight distance measures was less than an empirically determined threshold of 2,000, the floorplan in question was added to a cluster defined by the reference floor plan. Next, the first of the remaining floor plans that did not pass the threshold was designated a reference for the next cluster and the process repeated. Once all floor plans withing the same SOM cluster were assorted, the algorithm was reiterated on the next SOM cluster.

While the "refinement" algorithm could have been applied to the raw, unclustered data, the benefit of first creating the SOM clusters was a massive reduction of apartment-to-apartment comparisons and thus of computational resources.

This procedure yieded `r max(clusters$cluster)` rotation- and translation-invariant clusters of geometrically identical floor plans. The number of floor plans per cluster ranged from `r table(clusters$cluster) |> range() |> paste(collapse = " to ")` (see @fig-clust).


```{r}
#| fig-cap: Histogram of the distribution of number of floorplans per cluster
#| label: fig-clust
clusters |> group_by(cluster) |> tally() |> ggplot(aes(x = n)) + geom_histogram() + labs(x = "Number of floor plans per cluster")
```

## Filtering observations

Once the data was sorted into clusters accodring to the geometry of floor plans, we removed apartments that were deemed as essentially duplicates with respect to the values of average room noise and average room sunlight. These essential duplicates were identified as follows:

First, we discretised the noise variable into categories by 5 dB increments and the sunlight variable by increments of 200 lx.
Within each cluste and for each level of noise, we then retained one observation at every given level of the discretised sunlight variable (if available). The retained observation was the one with the lowest score on the original, continuous average room sunlight variable.

This further reduced the data set to the final size of _n_ = `r sum(clusters$keep)` essentially unique apartments.

