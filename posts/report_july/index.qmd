---
title: "Neufert 4.0 July 23 Progress Report"
author: "Milan Valášek"
date: "07/17/2023"
date-format: "D MMM YYYY"
categories: [Neufert 4.0, machine learning]
format: html
execute: 
  echo: false
  warning: false
  message: false
tbl-cap-location: bottom
---

<style>
    .table tr td, .table tr th {
        padding: .25rem .25rem;
    }
    .table {
        font-size: 0.875em;
    }
    .table-caption, caption {
        text-align: left;
    }
    caption > p {
        display: inline;
    }
</style>

```{r}
knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=",")
})
```

```{r}
library(reticulate)
library(ggplot2)
library(ggtext)
library(magrittr)
library(patchwork)

myColor = "#009194"
```


```{python}
from pickle import dump, load
import tensorflow as tf

with open('scaler_output.pkl', 'rb') as f:
    scaler_output = load(f)

scaler_means = scaler_output.named_transformers_["myscaler"].mean_
scaler_scales = scaler_output.named_transformers_["myscaler"].scale_

def preproc_df(df, cols, dict_names):
    out = dict(df[cols])
    for i, c in enumerate(cols):
        out[dict_names[i]] =  out.pop(c)
    return out

class CustomAccuracy(tf.keras.metrics.Metric):
    def __init__(self, name = 'accuracy', **kwargs):
        super(CustomAccuracy, self).__init__(**kwargs)
        self.hits = self.add_weight('acc', initializer = 'zeros')
        self.total = self.add_weight('acc', initializer = 'zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(y_true, tf.int32)
        y_pred = tf.cast(tf.math.round(y_pred), tf.int32)     
        n_hits = tf.equal(y_true, y_pred)
        self.hits.assign_add(tf.reduce_sum(tf.cast(n_hits, self.dtype)))        
        self.total.assign_add(tf.cast(tf.size(n_hits), self.dtype))

    def reset_state(self):
        self.hits.assign(0)
        self.total.assign(0)

    def result(self):
        return self.hits / self.total

model = tf.keras.models.load_model('23-07-13_affordance.keras', custom_objects={"CustomAccuracy": CustomAccuracy})
```


```{r}
df_y <- read.csv("output.csv")
x_test <- read.csv("x_test.csv")
y_test <- read.csv("y_test.csv")
x_train <- read.csv("x_train.csv")
```

## Motivation

We are attempting to build a deep neural network that would be able to predict likely characteristics of an apartment based solely on data derived from the geometry of its outline as well as basic variables related to the view from the apartment (_e.g._ whether or not a highway or railway is visible).

## Data

We made use of the Neufert 4.0 data based on the [Swiss dwellings dataset](https://zenodo.org/record/7070952). We reviewed the original data, removing duplicates, cleaning the data of errors, and adding apartment and floor outline geometries.
The resulting dataset contained `r nrow(df_y)` entries (one per apartment). Based on the data, we calculated `r ncol(x_train)` features that encoded geometrical and view properties of the individual apartments. These features were used as input variables for the neural network models.

As output variables, we chose a number of continuous and categorical variables:

```{r}
#| label: tbl-cont
#| tbl-cap: "Summary table of continuous outcome variables."
df_y |>
    dplyr::select(-c(id, has_balcony, number_of_rooms, has_loggia, has_second_bathroom, bathroom_has_window)) |>
    purrr::map_df(.f = ~ broom::tidy(summary(.x)), .id = "variable") |>
    dplyr::mutate(variable = stringr::str_to_sentence(gsub("_", " ", variable))) |>
    tidyr::replace_na(list("na" = 0)) |>
    kableExtra::kbl(
        col.names = c("Variable", "Min", "Q1", "Median", "Mean", "Q3", "Max", "Missing"),
        digits = 2) |>
    kableExtra::kable_styling()
```

```{r}
#| label: tbl-binary
#| tbl-cap: "Summary table of binary outcome variables."
df_y |>
    dplyr::select(has_loggia, bathroom_has_window) |>
    dplyr::mutate(
        has_loggia = as.logical(has_loggia),
        bathroom_has_window = as.logical(bathroom_has_window)) |>
    purrr::map_df(.f = ~ tibble::as_tibble(table(.x)), .id = "variable") |>
    tidyr::pivot_wider(id_cols = "variable", names_from = ".x", values_from = "n") |>
    dplyr::mutate(variable = stringr::str_to_sentence(gsub("_", " ", variable))) |>
    kableExtra::kbl(col.names = c("Variable", "No", "Yes")) |>
    kableExtra::kable_styling()
```

```{r}
#| label: fig-num-room
#| fig-cap: "Distribution of the `number_of_rooms variable."
ggplot(df_y) +
    geom_bar(aes(x = number_of_rooms), fill=myColor) +
    labs(x = "Number of rooms", y = "Count") +
    theme_bw()
```

The dataset was split into a training set (_N_ = `r nrow(x_train)`), development set (_N_ = `r nrow(x_test)`), and test set (_N_ = `r nrow(x_test)`). The development set was used for model evaluation during the hyperparameter tuning stage of the model development.

## General neural network architecture

The chosen neural network consisted of blocs of fully connected layers with L2 regularisation, followed by a dropout layer. For every but the first bloc, we also included a skip connection from the previous bloc. The number of units per layer, the value of regularisation parameter ($\lambda$), the dropout proportion, as well as the number of blocs in the network were treated as variable hyperparameters.
Finally, a single-unit layer for each of the eight outcome variables was added in parallel to the end of the last bloc.

## Hyperparameter search

We performed a grid search of the hyperparameter space defined by the following values:

- Dropout: [0.3, 0.4, 0.5]
- L2 regularisation parameter: [0.0001, 0.001, 0.01]
- No. of blocs: 1-7
- Number of units: [64, 128, 256]

The performance of the model was assessed according to the loss calculated on the validation set.

All models were trained using the Adam optimiser with a learning rate of 0.0001 for a maximum of 500 epochs. An early stopping rule was implemented with a patience of 20 epochs and a tolerance of 0.001, meaning that if the validation loss didn't improve for 20 epochs by more than 0.001, the training of the model was interrupted, reverting to the best weights to date.

## Best model architecture

Based on the hyperparameter tuning step described above, we settled on a model with the following characteristics:

- Dropout: 0.3
- L2 regularisation parameter: 0.0001
- No. of blocs: 5
- Number of units: 256

A graphical representation of the model can be found in @fig-model below.

:::{.column-screen-inset}
![Schema of the best-performing model](model.png){#fig-model}
:::

## Model performance


```{python}
#| include: false
cols = ['number_of_rooms', 'corridor_area_ratio', 'largest_room_kitchen_distance', 'largest_room_sunlight', 'largest_room_noise', 'kitchen_sunlight', 'has_loggia', 'bathroom_has_window']
loss_names = ["room_output",
    "efficiency_output",
    "kitchen_dist",
    "sunlight_output",
    "noise_output",
    "kitchen_sunlight",
    "loggia_output",
    "outer_bathroom"]

model_eval = model.evaluate(x=r.x_test, y=preproc_df(r.y_test, cols, loss_names))

pred = model.predict(x=r.x_test)
```


```{r}
conf_tab <- function(x) {
    tp = x[1]
    fp = x[2]
    tn = x[3]
    fn = x[4]
    data.frame(pos = c(tp, fp), neg = c(fn, tn)) %>%
        rbind(., colSums(.)) |>
        dplyr::mutate(
            tot = pos + neg,
            truth = c("Yes", "No", "Total"),
            y = c("", "Truth", "")) |>
        dplyr::select(y, truth, pos, neg, tot) |>
        kableExtra::kbl(
            col.names = c("", "", "Yes", "No", "Total"),
            table.attr = 'data-quarto-disable-processing="true"') |>
        kableExtra::kable_styling(bootstrap_options = c("striped", "condensed")) |>
        kableExtra::column_spec(1:2, bold = TRUE) |>
        kableExtra::add_header_above(c("", "", "Prediction" = 3)) |>
        kableExtra::footnote(paste0(c("Sensitivity: ", "Specificity: ", "Accuracy (not appropriate for imbalanced data): "), c(round(tp/(tp+fn) * 100, 1), round(tn / (tn+fp) * 100, 1), round((tp+tn)/(tp+fp+tn+fn) * 100, 1)), "%"), general_title = "")
}
```


### Does the apartment have a loggia?

In the table below, **sensitivity** refers to the ability of a test to detect and existing effect. If you have COVID, and take a PCR test, how likely is it to come back positive? **Specificity** on the other hand is the test's ability to accurately reject negative cases. If you do not have COVID, what is the probability that your PCR test comes back negative?

```{r}
#| label: tbl-loggia
#| tbl-cap: "Performance of the model with respect to the `has_loggia` variable."
conf_tab(py$model_eval[16:19])
```

### Does the bathroom have a window?

```{r}
#| label: tbl-bathroom
#| tbl-cap: "Performance of the model with respect to the `bathroom_has_window` variable."
conf_tab(py$model_eval[25:28])
```

### Number of rooms

Given the architecture of the network, the model predicted number of rooms as a continuous real number variable. For this reason, we rounded the prediction to whole number. Because the prediction domain was unconstrained, the model could predict a number of rooms smaller than one (this happened on two occasions) or larger than can reasonably be expected (on one occasion, it predicted 13 rooms).

These erroneous predictions aside, the model performance was as shown below:

```{r}
#| label: fig-rooms
#| fig-cap: "Confusion matrix of the number of rooms variable."
pred = round(py$pred[[1]])
ind = which(pred < 1 | pred > 6)

cm <- caret::confusionMatrix(factor(pred[-ind]), factor(y_test$number_of_rooms[-ind], levels = 1:6), dnn = c("Prediction", "Truth"))

plt <- as.data.frame(cm$table)
plt$Truth <- factor(plt$Truth, levels=rev(levels(plt$Truth)))

ggplot(plt, aes(Prediction, Truth, fill= Freq)) +
    geom_tile() + 
    geom_text(aes(label=Freq)) +
    scale_fill_gradient(low="white", high=myColor, guide = "none") +
    labs(x = "Truth", y = "Prediction") +
    theme_minimal()
```


The model correctly predicted the number of rooms for `r round(sum(diag(cm$table))/nrow(y_test) * 100, 1)`% of the cases, with only 21 (`r round(21/nrow(y_test) * 100, 2)`%) of predictions falling outside of the truth&pm;1 range.

### Continuous variables

The sections below provide a summary of the model performance on continuous variables. The scatter plots show the relationship between the model prediction and the ground truth based on the test set. Included in the plot is a OLS line of best fit along with an 80% prediction interval.

The _R_^2^ statistic can be interpreted as the proportion of variance in the outcome variable accounted for by the predictor.
The _b_ coefficients are the intercept and slope of the line of best fit and should ideally have the value of 0 and 1, respectively.

The left plot of the pair includes all data except for the outliers listed below. The plot on the right hand side also excludes observations where the true value is zero.

```{r}
scaler_names <- c('corridor_area_ratio','largest_room_sunlight', 'largest_room_noise', 'largest_room_kitchen_distance')
scaler_means <- py$scaler_means
names(scaler_means) <- scaler_names
scaler_scales <- py$scaler_scales
names(scaler_scales) <- scaler_names

plts <- list()
plts_clean <- list()
tbls <- list()
n_outliers <- c()
n_zero <- c()
pred_int_width <- c()
clean_lm <- list()
idx <- 1
for (i in c("corridor_area_ratio", "largest_room_kitchen_distance", "largest_room_sunlight", "largest_room_noise", "kitchen_sunlight")) {
    if (i %in% scaler_names) {
        var_mean <- scaler_means[i]
        var_sd <- scaler_scales[i]
    } else {
        var_mean <- 0
        var_sd <- 1
    }

    pred_df <- data.frame(prediction = py$pred[[which(py$cols == i)]] * var_sd + var_mean, truth = y_test[, i] * var_sd + var_mean)

    outliers <- which(abs(scale(pred_df$prediction)) > 7)
    plt_df <- pred_df
    if (length(outliers)) {
        plt_df <- pred_df[-outliers, ]
    }

    m <- lm(prediction ~ truth, plt_df)
    pred_int <- predict(m, interval = "prediction", level = .8) |>
        as.data.frame()
    pred_int$x = plt_df$truth

    plt_clean_df <- plt_df |> dplyr::filter(truth > 0)
    n_zero <- c(n_zero, plt_df |> dplyr::filter(truth == 0) |> nrow())

    m_clean <- lm(prediction ~ truth, plt_clean_df)
    pred_int_clean <- predict(m_clean, interval = "prediction", level = .8) |>
        as.data.frame()
    pred_int_clean$x = plt_clean_df$truth
    pred_int_width <- c(pred_int_width, round(mean(pred_int_clean$fit - pred_int_clean$lwr), 2))
    clean_lm[[idx]] = m_clean
    plts[[idx]] <- plt_df |>
        ggplot(aes(x = truth, y = prediction)) +
        geom_point(colour = myColor, alpha=.2) +
        geom_ribbon(data = pred_int, aes(x = x, y = NULL, ymin = lwr, ymax = upr), fill = "orangered", alpha = .2) +
        geom_smooth(method="lm", se=FALSE,colour = "orangered") + geom_richtext(data = data.frame(label = glue::glue("*R*<sup>2</sup> = {round(summary(lm(truth ~ prediction, plt_df))$r.squared, 2)}<br>_b_<sub>0</sub> = {round(coef(m)[1], 2)}<br>_b_<sub>1</sub> = {round(coef(m)[2], 2)}")), aes(x = Inf, y = -Inf, label = label), hjust = 1, vjust = -0.5, fill = NA, label.color = NA) +
        labs(x = "Truth", y = "Prediction") +
        theme_minimal()

    plts_clean[[idx]] <- plt_clean_df |>
        ggplot(aes(x = truth, y = prediction)) +
        geom_point(colour = myColor, alpha=.2) +
        geom_ribbon(data = pred_int_clean, aes(x = x, y = NULL, ymin = lwr, ymax = upr), fill = "orangered", alpha = .2) +
        geom_smooth(method="lm", se=FALSE,colour = "orangered") + geom_richtext(data = data.frame(label = glue::glue("*R*<sup>2</sup> = {round(summary(lm(truth ~ prediction, plt_clean_df))$r.squared, 2)}<br>_b_<sub>0</sub> = {round(coef(m_clean)[1], 2)}<br>_b_<sub>1</sub> = {round(coef(m_clean)[2], 2)}")), aes(x = Inf, y = -Inf, label = label), hjust = 1.5, vjust = -0.5, fill = NA, label.color = NA) +
        labs(x = "Truth", y = "Prediction") +
        theme_minimal()

    tbls[[idx]] <- pred_df[outliers, ] |>
        kableExtra::kbl(col.names = c( "Prediction", "Truth")) |>
        kableExtra::kable_styling()
    idx <- idx + 1
    n_outliers <- c(n_outliers, length(outliers))
}
```


```{r}
#| results: 'asis'

headings <- c(
    "Circulation efficiency", "Kitchen-living room distance (m)",
    "Living room sunlight (klx)", "Living room noise (dB)",
    "Kitchen sunlight (klx)"
)
for (i in 1:length(plts)) {
    cat("\n\n###", headings[i],"\n\n")
    print(plts[[i]] + plts_clean[[i]])
    cat("\n\n80% prediction interval = &pm;", pred_int_width[i], "\n\n", sep="")
    cat("\n\n_n_(x=0) =", n_zero[i], "\n\n")
    if (n_outliers[i]) {
        cat("\n\n**Outliers**\n\n")
        cat(tbls[[i]])
    }
}
```

